Section A
==========

1. Random Forest
---------------
Random Forest -P 100 -I 100 -num-slots 1 -K 0 -M 1.0 -V 0.001 -S 1

Time taken to build model: 0.13 seconds

Overall Accuracy: 78.41%

Confusion Matrix
   a   b   <-- classified as
 321  36 |   a = 0
 105 191 |   b = 1
 
 
2. Logistic Regression
----------------------
Logistic -R 1.0E-8 -M -1 -num-decimal-places 4
 
Time taken to build model: 2.17 seconds
 
Overall Accuracy: 73.97%
     
Confusion Matrix: 
   a   b   <-- classified as
 272  85 |   a = 0
  85 211 |   b = 1
  

3. Multi-layer Perceptron
--------------------------
MultilayerPerceptron -L 0.3 -M 0.2 -N 10 -V 0 -S 0 -E 20 -H a 

Time taken to build model: 110.6 seconds

Overall Accuracy: 78.87%

Confusion Matrix: 
   a   b   <-- classified as
 280  77 |   a = 0
  61 235 |   b = 1
  

4. SVM 
------
SGD -F 0 -L 0.01 -R 1.0E-4 -E500 -C 0.001 -S 1

Time taken to build model: 0.69 seconds

Overall Accuracy: 85.5%
     
Confusion Matrix: 
   a   b   <-- classified as
 308  49 |   a = 0
  46 250 |   b = 1

5. Decision Table
------------------
DecisionTable -X 1 -S"weka.attributeSelection.BestFirst -D 1 -N 5"

Time taken to build model: 0.06 seconds

Overall Accuracy: 85.9%

Confusion Matrix: 
   a   b   <-- classified as
 304  53 |   a = 0
  39 257 |   b = 1
  
Section B
==========

1. Random Forest
---------------
Random Forest -P 100 -I 110 -num-slots 1 -K 0 -M 1.0 -V 0.001 -S 1

Time taken to build model: 0.17 seconds

Overall Accuracy: 78.56%

Confusion Matrix
   a   b   <-- classified as
 322  35 |   a = 0
 105 191 |   b = 1
 
I modified number of iterations to 110
Runtime increased by 0.04seconds
Accuracy improved by 0.15% 
It was because Random Forest might show some improvement with increased number of iterations.
 
 
 2. Logistic Regression
----------------------
Logistic -R 1.0E-4 -M -1 -num-decimal-places 4
 
Time taken to build model: 11.56 seconds
 
Overall Accuracy: 78.4%
     
Confusion Matrix: 
   a   b   <-- classified as
 295  62 |   a = 0
  79 217 |   b = 1
  
I modified ridge estimator in log likelihood to 1.0E-4
Runtime increased by 9.39seconds
Accuracy improved by 4.43% 
It's because ridge estimators can be used in Logistic Regression to improve the parameter estimates and to 
reduce error made by further predictions.
  
(Reference: https://www.jstor.org/stable/2347628?seq=1#page_scan_tab_contents)


3. Multi-layer Perceptron
--------------------------
MultilayerPerceptron -L 0.3 -M 0.2 -N 4 -V 0 -S 0 -E 20 -H a 

Time taken to build model: 47.06 seconds

Overall Accuracy: 73.8%

Confusion Matrix: 
   a   b   <-- classified as
 275  82 |   a = 0
  89 207 |   b = 1

I modified trainingTime to 4.
Runtime reduced by 63.54 seconds
Accuracy worsen by 5.07% 
Reducing the trainingTime reduces number of epochs to train through. So the model accuracy decreased. 
It reduced the time taken to build model significantly.


4. SVM 
------
SGD -F 1 -L 0.01 -R 1.0E-4 -E500 -C 0.001 -S 1

Time taken to build model: 1.05 seconds

Overall Accuracy: 86.68%
     
Confusion Matrix: 
   a   b   <-- classified as
 311  46 |   a = 0
  41 255 |   b = 1
  
I modified lossFunction to Log loss
Runtime increased by 0.36 seconds
Accuracy improved by 1.18% 
Change is because choosing loss function has impacts on classification and thus accuracy of model. 

5. Decision Table
------------------
DecisionTable -X 1 -S"weka.attributeSelection.GreedyStepwise -T --1.7976931348623157E308 -N -1 -num-slots 1"

Time taken to build model: 0.02 seconds

Overall Accuracy: 86.37%

Confusion Matrix: 
   a   b   <-- classified as
 286  71 |   a = 0
  18 278 |   b = 1
  
I modified search method to GreedyStepWise.
Runtime reduced by 0.04 seconds
Accuracy improved by 0.47% 
Since search method is used to select the good attribute for classification, it impacts the model accuracy.

2. Weka random forest accuracy is approximately 78% using default and modified parameters. 
In Q2, approximate accuracy is 99%. Using entropy and information gain to choose split attribute, derive split value
using mean for numerical attributes and mode for categorical attributes, avoiding overfitting, allowed the model to
provide better accuracy.

3. Among 5 approaches I liked the SGD (Stochastic Gradient Descent) implementation of linear model using logistic regression.
Model details which I considered, and appear to be better than other models are: 
Overall accuracy of 86.68% 
Time taken to build model 1.05 seconds
Total Positive rate is 86.7% and False positive rate is 13.4%. 
Confusion Matrix: 
   a   b   <-- classified as
 311  46 |   a = 0
  41 255 |   b = 1

 
